{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af5e746-5d74-4142-a9de-f07f88810767",
   "metadata": {},
   "source": [
    "# Hamming Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26490a-6e07-49b8-9a3e-dedd681fab4b",
   "metadata": {},
   "source": [
    "__Hamming Diversity__ is calculated by keeping a count of the occurence of a token in previous time steps / groups. It penalise using same token in current group which was used in previous groups at the same time step.\n",
    "See [Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models](https://arxiv.org/pdf/1610.02424.pdf) for more details.\n",
    "\n",
    "\n",
    "Args:<br>\n",
    "* __diversity_penalty (`float`):__<br>\n",
    "        This value is subtracted from a beam's score if it generates a token same as any beam from other group at a\n",
    "        particular time. Note that `diversity_penalty` is only effective if `group beam search` is enabled. diversity_penalty parameter during beam search with Hamming Diversity can influence the diversity and creativity of the generated text.<br>\n",
    "*  __num_beams (`int`):__<br>\n",
    "        Number of beams used for group beam search. Increasing num_beams generally increases diversity by exploring more alternative sequences or beams in parallel. `num_beams` should be divisible by `num_beam_groups` for group beam search.<br>\n",
    "* __num_beam_groups (`int`):__<br>\n",
    "        Number of groups to divide `num_beams` into in order to ensure diversity among different groups of beams. Increasing num_beam_groups encourages diversity within each group, promoting varied sequences within the same group and reducing repetition across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24cd7ff4-d9f5-4e9d-a599-3f62217a9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57df68f-64eb-4c31-8487-a8b05ac16bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With limiting the generated sequence to six tokens\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "inputs = tokenizer([\"Artificial intelligence is transforming industries\"], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5f3c0-3650-4e50-96dc-54588e8d49e5",
   "metadata": {},
   "source": [
    "## 1. With a moderate diversity penalty, you aim to strike a balance between generating varied outputs and maintaining coherence. The outputs might have a mix of diverse and relevant content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39e56b5-04dc-4390-8af4-ca368ae99990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is transforming industries, and it's not just\n"
     ]
    }
   ],
   "source": [
    "beam_ids = model.generate(inputs[\"input_ids\"], num_beams=2, num_beam_groups = 2, diversity_penalty = 0.5, max_new_tokens=6) \n",
    "print(tokenizer.batch_decode(beam_ids, skip_special_tokens=True)[0])\n",
    "#Artificial intelligence is transforming industries, and it's not just"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee083a1-2990-4cfe-89e9-bdf9767cf5b6",
   "metadata": {},
   "source": [
    "## 2. Increasing the number of beams allows the model to explore more alternatives in parallel. However, since the beam groups remain limited, you might still observe repetition in the generated sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df98a92b-c1ad-44d5-9251-93a0409bdc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is transforming industries, and it's not just\n"
     ]
    }
   ],
   "source": [
    "beam_ids = model.generate(inputs[\"input_ids\"], num_beams=4, num_beam_groups = 2, diversity_penalty = 0.5, max_new_tokens=6)\n",
    "print(tokenizer.batch_decode(beam_ids, skip_special_tokens=True)[0])\n",
    "#Artificial intelligence is transforming industries, and it's not just"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe066de-580e-407c-92b8-5afc18bb23de",
   "metadata": {},
   "source": [
    "## 3. With more beams, there's a higher likelihood of exploring diverse possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90abec7-1829-4cb3-9c01-543171c334e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is transforming industries and the lives of millions of\n"
     ]
    }
   ],
   "source": [
    "beam_ids = model.generate(inputs[\"input_ids\"], num_beams=8, num_beam_groups = 2, diversity_penalty = 0.5, max_new_tokens=6)\n",
    "print(tokenizer.batch_decode(beam_ids, skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9055962-3ba4-41f0-8754-25eea7090f2e",
   "metadata": {},
   "source": [
    "## 4. With more beam groups, the model can explore different sequences within and across groups, increasing diversity. However, the relatively low diversity penalty might still lead to some repetition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93b8001-cc67-4ac9-b821-7b68f5e0e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is transforming industries, and it's not just\n"
     ]
    }
   ],
   "source": [
    "beam_ids = model.generate(inputs[\"input_ids\"], num_beams=4, num_beam_groups = 4, diversity_penalty = 0.5, max_new_tokens=6)\n",
    "print(tokenizer.batch_decode(beam_ids, skip_special_tokens=True)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6aed94-89a7-49fd-8410-3fa985cba8f7",
   "metadata": {},
   "source": [
    "## 5. A high diversity penalty promotes diversity at the expense of coherence. The generated outputs might become more fragmented and less coherent due to the aggressive avoidance of repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ebdafb-e902-4188-82e8-d6524ae160fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is transforming industries like healthcare, education, and\n"
     ]
    }
   ],
   "source": [
    "beam_ids = model.generate(inputs[\"input_ids\"], num_beams=4, num_beam_groups = 4, diversity_penalty = 10.9, max_new_tokens=6)\n",
    "print(tokenizer.batch_decode(beam_ids, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf080c-416d-4f11-b412-3a2661a2b973",
   "metadata": {},
   "source": [
    "__Overall, these examples showcase how different combinations of num_beams, num_beam_groups, and diversity_penalty can influence the level of diversity and coherence in the generated outputs. Note the output is highly depend on the pretrained model that has been chosen.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac69b9a-cce7-46ce-8b64-a5455716144e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2425462f-406f-4ab4-a468-0de51b235363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
